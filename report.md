### Pruning and Evaluation Function
The pruning function is a simple, by-the-book minimax algorithm with alpha-beta pruning. I initially implemented the minimax algorithm without pruning, but found that pruning allowed me to double my search depth while remaining well within the 10 minute time limit. To implement both algorithms, I took the pseudocode on Wikipedia and implemented it according to the needs of my bot. The largest modification I made was to return the best move instead of the best heuristic value of a child node, since the bot needs to return a valid move each turn.

I'm still nailing down my heuristic function, but the changes I've made so far seem to be improving my bot's performance. So far, I create a total heuristic from four subparts, inspired by Kartik Kukreja's [blog post](https://kartikkukreja.wordpress.com/2013/03/30/heuristic-function-for-reversiothello/):
1. Parity, or the difference in coins between the minimizing and maximizing player
2. Mobility, or the difference in the number of possible moves between the minimizing and maximizing player
3. Corners, or the difference in the number of corners occupied by the minimizing and maximizing player
4. Stability, or the ability of each piece to be taken by the opponent
A deeper dive into the reasons these heuristics were selected will be given in the evaluation section. The total heuristic is calculated by adding the subparts after multiplying them by preset weights. Mobility has a weight of 2, corners have a weight of 60, and stability has a weight of 4. These weights can almost certainly be improved with more testing and analysis.

You may have noticed that a weight was not given for the parity heuristic above. For my creative portion, I tested giving parity a special dynamic weight that changes based on progress in the game. Initial positioning is much more important than the number of pieces taken, but as the game progresses, it becomes more and more important to take pieces, since the player with the most pieces will win the game. My weight is calculated as squares_taken / total_squares * 10.
### Time Spent
I, Josh Klingonsmith, worked alone and spent about 7 hours on the project. I intend to continue refining my algorithm, but am submitting what I have so far in the interest of time.
### Algorithm Evaluation
Although I was impressed with how quickly the algorithm came together, I recognize that my bot still has a long way to go. It consistently beats the random player by a solid margin, and has beaten me before, but could definitely still be beat my a more experienced human player. Here are a few variations of my algorithm that I tested before settling on the current iteration:
- One of the most pervasive issues to plague my algorithm was a hard-coded maximizing player. As I started the algorithm, I didn't fully understand it, and thought that the maximizing player could be arbitrary. However, in my testing I came to realize that if I set my bot to go first instead of second, it would actually minimize its score and maximize the opponent's. Once I discovered this, it was relatively easy to fix by setting the maximizing player based on the turn number assigned to the bot.
- Initially, my heuristic only considered parity, mobility, and corners, since I wasn't sure how to implement the stability heuristic. However, this caused my algorithm to ignore opportunities to take side pieces, which is a critical part of Reversi. Eventually, I decided to implement a simple version of stability where each piece with an empty spot next to it has a stability value of -1, each piece that cannot be taken has a value of 1, and all other pieces have a value of 0. I recognize that this is a quick and dirty solution, and it is one of the first things I'd like to improve as I continue to work on my algorithm.
- I started with a (seemingly) high corners coefficient of 10, but I found that my algorithm was still constantly giving up corners to the opponent. Since corners cannot be retaken and are central to a winning Reversi strategy, I bumped up the coefficient to 60. Putting a much higher value on corners helped, but my algorithm still inexplicably gives up corners when it seems like it shouldn't. This is another thing that I would like to investigate.
- Originally, I used a constant parity coefficient of 1, but found that my algorithm was overly aggressive in picking up pieces at the start of the game. I wanted to find a way to force my algorithm to focus on positioning first, then pieces as the game went on. Ultimately, I found a simple way of doing this by giving the parity heuristic a dynamic coefficient that increases up to 10 as the game progresses (as more pieces are taken). As soon as I implemented this change, my algorithm improved noticeably.

The elements of my heuristic function were included for the following reasons:
- Parity - ultimately, the goal of the game is to end with more pieces on the board than your opponent. This metric considers the number of tokens belonging to the maximizing player compared to the minimizing player. As mentioned above, its weight increases as the game goes on, since the number of pieces controlled becomes more important as the game comes to a close.
- Mobility - having more move options, even if many of the options are suboptimal, generally means that a player has the upper hand. This metric compares the number of moves available to the maximizing and minimizing players.
- Corners - this simple metric compares the number of corners owned by the maximizing and minimizing players. Corners are especially powerful in Reversi because they cannot be flipped, and have an correspondingly high coefficient of 60.
- Stability - this metric strives to represent the security of a player's pieces. Pieces that are most likely to be flipped are given a negative score, while pieces that cannot be taken are given a positive score.

Timing is another place where my algorithm may stand in need of improvement. Currently, my algorithm always finishes in less than half of its allotted time (10 minutes), but I can't find a way to improve my results by taking more time without leaving the 10 minute window. The depth of my minimax search is currently up to 6, but setting it even to 7 drastically increases the number of game states it needs to process. I suspect that I could deal with this using a lookup table, but I have not had time to test that so far. In its current form, the algorithm takes no longer than about 30 seconds to return a single move, but on the majority of moves returns much faster. The algorithm is fast (as little as a second or less) at the beginning and end of the game when there are fewer possible moves, but in the middle when there are many options, the time taken jumps significantly.
